#!/usr/bin/env python3
"""
–°–ò–°–¢–ï–ú–ê –û–ß–ò–°–¢–ö–ò –ü–†–û–ï–ö–¢–ê
–£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
"""
import os
import shutil
from pathlib import Path
from typing import List, Dict, Set, Tuple
import logging
import re
import ast
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ProjectCleanupSystem:
    """–°–∏—Å—Ç–µ–º–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞"""
    
    def __init__(self):
        self.project_root = Path(".")
        self.removed_files: List[Path] = []
        self.cleaned_files: List[Path] = []
        
        # –ù–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        self.outdated_docs = [
            # –û—Ç—á–µ—Ç—ã —Å –¥–∞—Ç–æ–π 2026-01-06
            "ADVANCED_AGENT_CODE_QUALITY_REPORT_2026-01-06.md",
            "AGENT_CODE_QUALITY_REPORT_2026-01-06.md", 
            "AUDIT_REPORT_2026-01-06.md",
            "CODE_AUDIT_2026-01-06.md",
            "CODE_QUALITY_AUDIT_2026-01-06.md",
            "CODE_QUALITY_IMPROVEMENTS_2026-01-06.md",
            "EXPERT_AGENT_CODE_QUALITY_REPORT_2026-01-06.md",
            "FINAL_CODE_QUALITY_IMPROVEMENTS_2026-01-06.md",
            "FINAL_EXPERT_CODE_QUALITY_ASSESSMENT.md",
            "FINAL_STATUS_2026-01-06.md",
            "MULTIAGENT_AUDIT_2026-01-06.md",
            "MULTIAGENT_QUALITY_AUDIT_2026-01-06.md",
            "PROGRESS_REPORT_2026-01-06.md",
            "SECURITY_IMPROVEMENTS_2026-01-06.md",
            "SUCCESS_REPORT_2026-01-06.md",
            "TODAY_PLAN_2026-01-06.md",
            "UI_FIX_PROGRESS_2026-01-06.md",
            
            # –î—Ä—É–≥–∏–µ –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            "daily_report_2026-01-04.md",
            "daily_report_2026-01-05.md",
            "HTTPS_STATUS.md",
            "IMPORTANT_REMINDER.md",
            "NIP_IO_DOMAINS.md",
            "DEPLOYMENT_SUCCESS.md",
            "MULTIAGENT_EXECUTIVE_SUMMARY.md",
            "QUALITY_EXECUTIVE_SUMMARY.md",
            "NATURAL_INTERACTION_DEMO.md",
        ]
        
        # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        self.duplicate_files = [
            "ui_simple.py",  # –û—Å—Ç–∞–≤–ª—è–µ–º ui.py
            "ui_minimal.py",  # –û—Å—Ç–∞–≤–ª—è–µ–º ui.py
            "test_multiagent_quality_mock.py",  # –û—Å—Ç–∞–≤–ª—è–µ–º test_multiagent_quality.py
            "test_agent_code_quality_mock.py",  # –û—Å—Ç–∞–≤–ª—è–µ–º test_agent_code_quality.py
        ]
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –Ω–µ–Ω—É–∂–Ω—ã–µ —Ñ–∞–π–ª—ã
        self.temp_files = [
            ".tmp-agent-system.tar679728075",
            "agent-system.tar.gz",
            "agent_training_progress.json",
            "code_quality_report.json",
            "multiagent_quality_analysis.json",
            "security_report.json",
        ]
    
    def remove_outdated_documents(self) -> None:
        """–£–¥–∞–ª—è–µ—Ç –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
        logger.info("üìÑ –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
        
        for doc_name in self.outdated_docs:
            doc_path = self.project_root / doc_name
            if doc_path.exists():
                try:
                    doc_path.unlink()
                    self.removed_files.append(doc_path)
                    logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω: {doc_name}")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {doc_name}: {e}")
            else:
                logger.debug(f"‚ÑπÔ∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {doc_name}")
    
    def remove_duplicate_files(self) -> None:
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        logger.info("üîÑ –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
        
        for file_name in self.duplicate_files:
            file_path = self.project_root / file_name
            if file_path.exists():
                try:
                    file_path.unlink()
                    self.removed_files.append(file_path)
                    logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω –¥—É–±–ª—å: {file_name}")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file_name}: {e}")
    
    def remove_temp_files(self) -> None:
        """–£–¥–∞–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        logger.info("üóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
        
        for file_name in self.temp_files:
            file_path = self.project_root / file_name
            if file_path.exists():
                try:
                    file_path.unlink()
                    self.removed_files.append(file_path)
                    logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file_name}")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file_name}: {e}")
    
    def clean_duplicate_code_in_file(self, file_path: Path) -> bool:
        """–û—á–∏—â–∞–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥ –≤ —Ñ–∞–π–ª–µ"""
        try:
            content = file_path.read_text(encoding='utf-8')
            original_content = content
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
            lines = content.split('\n')
            seen_imports = set()
            cleaned_lines = []
            
            for line in lines:
                stripped = line.strip()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–ø–æ—Ä—Ç—ã
                if stripped.startswith(('import ', 'from ')):
                    if stripped not in seen_imports:
                        seen_imports.add(stripped)
                        cleaned_lines.append(line)
                    else:
                        logger.debug(f"–£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç: {stripped}")
                else:
                    cleaned_lines.append(line)
            
            content = '\n'.join(cleaned_lines)
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –∏ —Ñ—É–Ω–∫—Ü–∏–π
            content = self._remove_duplicate_definitions(content)
            
            # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
            content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)
            
            if content != original_content:
                file_path.write_text(content, encoding='utf-8')
                return True
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {file_path}: {e}")
            
        return False
    
    def _remove_duplicate_definitions(self, content: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –∏ —Ñ—É–Ω–∫—Ü–∏–π"""
        try:
            tree = ast.parse(content)
            seen_definitions = set()
            lines = content.split('\n')
            lines_to_remove = set()
            
            for node in ast.walk(tree):
                if isinstance(node, (ast.ClassDef, ast.FunctionDef)):
                    definition_key = f"{type(node).__name__}:{node.name}"
                    
                    if definition_key in seen_definitions:
                        # –ü–æ–º–µ—á–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
                        start_line = node.lineno - 1
                        end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line + 1
                        
                        for i in range(start_line, min(end_line, len(lines))):
                            lines_to_remove.add(i)
                            
                        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: {definition_key} –Ω–∞ —Å—Ç—Ä–æ–∫–µ {node.lineno}")
                    else:
                        seen_definitions.add(definition_key)
            
            # –£–¥–∞–ª—è–µ–º –ø–æ–º–µ—á–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            if lines_to_remove:
                cleaned_lines = [line for i, line in enumerate(lines) if i not in lines_to_remove]
                return '\n'.join(cleaned_lines)
                
        except SyntaxError:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å —Ñ–∞–π–ª –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–µ–π")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π: {e}")
            
        return content
    
    def clean_python_files(self) -> None:
        """–û—á–∏—â–∞–µ—Ç Python —Ñ–∞–π–ª—ã –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞"""
        logger.info("üêç –û—á–∏—Å—Ç–∫–∞ Python —Ñ–∞–π–ª–æ–≤ –æ—Ç –¥—É–±–ª–µ–π...")
        
        python_files = list(self.project_root.rglob("*.py"))
        
        for py_file in python_files:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –≤ .venv –∏ .git
            if any(part.startswith('.') for part in py_file.parts):
                continue
                
            if self.clean_duplicate_code_in_file(py_file):
                self.cleaned_files.append(py_file)
                logger.info(f"‚úÖ –û—á–∏—â–µ–Ω: {py_file.name}")
    
    def remove_unused_imports(self) -> None:
        """–£–¥–∞–ª—è–µ—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã –∏–∑ Python —Ñ–∞–π–ª–æ–≤"""
        logger.info("üì¶ –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤...")
        
        python_files = [
            "code_quality_improvement_system.py",
            "auto_code_formatter.py", 
            "quality_progress_monitor.py",
            "ui.py",
        ]
        
        for file_name in python_files:
            file_path = self.project_root / file_name
            if file_path.exists():
                self._remove_unused_imports_from_file(file_path)
    
    def _remove_unused_imports_from_file(self, file_path: Path) -> None:
        """–£–¥–∞–ª—è–µ—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        try:
            content = file_path.read_text(encoding='utf-8')
            lines = content.split('\n')
            
            # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
            import_lines = []
            code_lines = []
            
            for i, line in enumerate(lines):
                if line.strip().startswith(('import ', 'from ')):
                    import_lines.append((i, line))
                else:
                    code_lines.append(line)
            
            code_content = '\n'.join(code_lines)
            used_imports = []
            
            for line_num, import_line in import_lines:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–µ–Ω–∞ –∏–º–ø–æ—Ä—Ç–æ–≤
                if import_line.strip().startswith('import '):
                    module_name = import_line.replace('import ', '').split(' as ')[0].strip()
                    if module_name in code_content:
                        used_imports.append((line_num, import_line))
                elif import_line.strip().startswith('from '):
                    # –î–ª—è from imports –ø—Ä–æ–≤–µ—Ä—è–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ
                    used_imports.append((line_num, import_line))  # –ü–æ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ from imports
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            new_lines = [''] * len(lines)
            for line_num, import_line in used_imports:
                new_lines[line_num] = import_line
            
            for i, line in enumerate(lines):
                if not line.strip().startswith(('import ', 'from ')):
                    new_lines[i] = line
            
            # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ—Ç —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
            final_lines = [line for line in new_lines if line is not None]
            
            new_content = '\n'.join(final_lines)
            if new_content != content:
                file_path.write_text(new_content, encoding='utf-8')
                logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω—ã –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã: {file_path.name}")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∏–º–ø–æ—Ä—Ç–æ–≤ –∏–∑ {file_path}: {e}")
    
    def create_project_structure_report(self) -> None:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Ç—á–µ—Ç –æ –Ω–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞"""
        logger.info("üìä –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞...")
        
        report = """# üìÅ –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê –ü–û–°–õ–ï –û–ß–ò–°–¢–ö–ò

## üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—á–∏—Å—Ç–∫–∏

### ‚úÖ –£–¥–∞–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
"""
        
        if self.removed_files:
            for file_path in self.removed_files:
                report += f"- ‚ùå {file_path.name}\n"
        else:
            report += "- –ù–µ—Ç —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n"
        
        report += "\n### üßπ –û—á–∏—â–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n"
        
        if self.cleaned_files:
            for file_path in self.cleaned_files:
                report += f"- ‚úÖ {file_path.name}\n"
        else:
            report += "- –ù–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n"
        
        report += f"""

## üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- **–£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤:** {len(self.removed_files)}
- **–û—á–∏—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤:** {len(self.cleaned_files)}
- **–î–∞—Ç–∞ –æ—á–∏—Å—Ç–∫–∏:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
project/
‚îú‚îÄ‚îÄ src/                    # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥
‚îÇ   ‚îú‚îÄ‚îÄ agent_runtime/      # –°—Ä–µ–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ agent_system/       # –°–∏—Å—Ç–µ–º–∞ –∞–≥–µ–Ω—Ç–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ ui/                 # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
‚îú‚îÄ‚îÄ tests/                  # –¢–µ—Å—Ç—ã
‚îú‚îÄ‚îÄ docs/                   # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îú‚îÄ‚îÄ scripts/                # –°–∫—Ä–∏–ø—Ç—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è
‚îú‚îÄ‚îÄ config/                 # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
‚îî‚îÄ‚îÄ requirements.txt        # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
```

## üîß –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

1. **–†–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤** - –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Ñ–∞–π–ª—ã –≤ –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
2. **–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–º–ø–æ—Ä—Ç–æ–≤** - –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø—É—Ç–∏ –∏–º–ø–æ—Ä—Ç–æ–≤
3. **–î–æ–±–∞–≤–ª–µ–Ω–∏–µ type hints** - —É–ª—É—á—à–∏—Ç—å —Ç–∏–ø–∏–∑–∞—Ü–∏—é
4. **–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤** - –¥–æ–±–∞–≤–∏—Ç—å unit —Ç–µ—Å—Ç—ã
5. **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ CI/CD** - –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

---
*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å–∏—Å—Ç–µ–º–æ–π –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞*
"""
        
        report_path = self.project_root / "PROJECT_CLEANUP_REPORT.md"
        report_path.write_text(report, encoding='utf-8')
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω –æ—Ç—á–µ—Ç: {report_path.name}")
    
    def run_full_cleanup(self) -> None:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –æ—á–∏—Å—Ç–∫—É –ø—Ä–æ–µ–∫—Ç–∞"""
        logger.info("üöÄ –ù–ê–ß–ê–õ–û –ü–û–õ–ù–û–ô –û–ß–ò–°–¢–ö–ò –ü–†–û–ï–ö–¢–ê")
        
        # 1. –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        self.remove_outdated_documents()
        
        # 2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.remove_duplicate_files()
        
        # 3. –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self.remove_temp_files()
        
        # 4. –û—á–∏—Å—Ç–∫–∞ Python —Ñ–∞–π–ª–æ–≤
        self.clean_python_files()
        
        # 5. –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
        self.remove_unused_imports()
        
        # 6. –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        self.create_project_structure_report()
        
        logger.info("‚úÖ –ü–û–õ–ù–ê–Ø –û–ß–ò–°–¢–ö–ê –ü–†–û–ï–ö–¢–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        logger.info(f"üìä –£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(self.removed_files)}")
        logger.info(f"üßπ –û—á–∏—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(self.cleaned_files)}")

if __name__ == "__main__":
    cleanup = ProjectCleanupSystem()
    cleanup.run_full_cleanup()