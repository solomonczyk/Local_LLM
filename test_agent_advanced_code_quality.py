"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ –∞–≥–µ–Ω—Ç–æ–≤ - —Å–ª–æ–∂–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
"""
import ast
import json
import time
import re
from typing import Dict, List, Any

class AdvancedAgentCodeQualityTester:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç–µ—Ä –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞"""
    
    def __init__(self):
        # –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞–≥–µ–Ω—Ç—ã
        self.advanced_code_examples = {
            "design_patterns": '''from abc import ABC, abstractmethod
from typing import List, Optional
from enum import Enum

class PaymentStatus(Enum):
    """–°—Ç–∞—Ç—É—Å—ã –ø–ª–∞—Ç–µ–∂–∞."""
    PENDING = "pending"
    COMPLETED = "completed"
    FAILED = "failed"
    REFUNDED = "refunded"

class PaymentProcessor(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–ª–∞—Ç–µ–∂–µ–π."""
    
    @abstractmethod
    def process_payment(self, amount: float, currency: str) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–ª–∞—Ç–µ–∂."""
        pass
    
    @abstractmethod
    def validate_payment_data(self, payment_data: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∞."""
        pass

class CreditCardProcessor(PaymentProcessor):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø–ª–∞—Ç–µ–∂–µ–π –ø–æ –∫—Ä–µ–¥–∏—Ç–Ω—ã–º –∫–∞—Ä—Ç–∞–º."""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self._transaction_log: List[Dict[str, Any]] = []
    
    def process_payment(self, amount: float, currency: str = "USD") -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–ª–∞—Ç–µ–∂ –ø–æ –∫—Ä–µ–¥–∏—Ç–Ω–æ–π –∫–∞—Ä—Ç–µ.
        
        Args:
            amount: –°—É–º–º–∞ –ø–ª–∞—Ç–µ–∂–∞
            currency: –í–∞–ª—é—Ç–∞ –ø–ª–∞—Ç–µ–∂–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–ª–∞—Ç–µ–∂–∞
            
        Raises:
            ValueError: –ü—Ä–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            PaymentError: –ü—Ä–∏ –æ—à–∏–±–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        if amount <= 0:
            raise ValueError("–°—É–º–º–∞ –ø–ª–∞—Ç–µ–∂–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π")
        
        if currency not in ["USD", "EUR", "RUB"]:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –≤–∞–ª—é—Ç–∞: {currency}")
        
        try:
            # –°–∏–º—É–ª—è—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–ª–∞—Ç–µ–∂–∞
            transaction_id = f"txn_{int(time.time())}"
            
            result = {
                "transaction_id": transaction_id,
                "amount": amount,
                "currency": currency,
                "status": PaymentStatus.COMPLETED.value,
                "timestamp": time.time()
            }
            
            self._transaction_log.append(result)
            return result
            
        except Exception as e:
            error_result = {
                "error": str(e),
                "status": PaymentStatus.FAILED.value,
                "timestamp": time.time()
            }
            self._transaction_log.append(error_result)
            raise PaymentError(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–ª–∞—Ç–µ–∂–∞: {e}")
    
    def validate_payment_data(self, payment_data: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–ª–∞—Ç–µ–∂–∞."""
        required_fields = ["card_number", "expiry_date", "cvv", "amount"]
        
        for field in required_fields:
            if field not in payment_data:
                return False
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        card_number = payment_data.get("card_number", "")
        if not card_number.isdigit() or len(card_number) != 16:
            return False
        
        return True

class PaymentError(Exception):
    """–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –æ—à–∏–±–æ–∫ –ø–ª–∞—Ç–µ–∂–µ–π."""
    pass''',
            
            "async_architecture": '''import asyncio
import aiohttp
import logging
from typing import Dict, List, Optional, Callable, Any
from dataclasses import dataclass
from contextlib import asynccontextmanager

@dataclass
class APIEndpoint:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è API endpoint."""
    url: str
    method: str = "GET"
    timeout: int = 30
    retries: int = 3
    headers: Optional[Dict[str, str]] = None

class AsyncAPIClient:
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ API.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    - Retry –ª–æ–≥–∏–∫—É —Å exponential backoff
    - Circuit breaker pattern
    - Rate limiting
    - –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤
    """
    
    def __init__(self, max_concurrent: int = 10, rate_limit: int = 100):
        self.max_concurrent = max_concurrent
        self.rate_limit = rate_limit
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.rate_limiter = asyncio.Semaphore(rate_limit)
        self.cache: Dict[str, Any] = {}
        self.circuit_breaker_failures: Dict[str, int] = {}
        self.logger = logging.getLogger(__name__)
    
    @asynccontextmanager
    async def session(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è HTTP —Å–µ—Å—Å–∏–∏."""
        connector = aiohttp.TCPConnector(limit=100, limit_per_host=30)
        timeout = aiohttp.ClientTimeout(total=60)
        
        async with aiohttp.ClientSession(
            connector=connector,
            timeout=timeout
        ) as session:
            yield session
    
    async def fetch_single(
        self, 
        endpoint: APIEndpoint, 
        session: aiohttp.ClientSession,
        cache_key: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–∏–Ω HTTP –∑–∞–ø—Ä–æ—Å —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫.
        
        Args:
            endpoint: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è endpoint
            session: HTTP —Å–µ—Å—Å–∏—è
            cache_key: –ö–ª—é—á –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –û—Ç–≤–µ—Ç API –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—à–∏–±–∫–µ
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if cache_key and cache_key in self.cache:
            self.logger.info(f"Cache hit for {cache_key}")
            return self.cache[cache_key]
        
        # Circuit breaker check
        if self.circuit_breaker_failures.get(endpoint.url, 0) > 5:
            return {"error": "Circuit breaker open", "url": endpoint.url}
        
        async with self.semaphore:  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ concurrent –∑–∞–ø—Ä–æ—Å–æ–≤
            async with self.rate_limiter:  # Rate limiting
                for attempt in range(endpoint.retries):
                    try:
                        async with session.request(
                            endpoint.method,
                            endpoint.url,
                            headers=endpoint.headers or {},
                            timeout=aiohttp.ClientTimeout(total=endpoint.timeout)
                        ) as response:
                            
                            if response.status == 200:
                                data = await response.json()
                                result = {
                                    "data": data,
                                    "status": response.status,
                                    "url": endpoint.url,
                                    "attempt": attempt + 1
                                }
                                
                                # –ö—ç—à–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
                                if cache_key:
                                    self.cache[cache_key] = result
                                
                                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫
                                self.circuit_breaker_failures[endpoint.url] = 0
                                
                                return result
                            else:
                                self.logger.warning(f"HTTP {response.status} for {endpoint.url}")
                                
                    except asyncio.TimeoutError:
                        self.logger.error(f"Timeout for {endpoint.url} (attempt {attempt + 1})")
                        if attempt < endpoint.retries - 1:
                            await asyncio.sleep(2 ** attempt)  # Exponential backoff
                    
                    except Exception as e:
                        self.logger.error(f"Error for {endpoint.url}: {e}")
                        if attempt < endpoint.retries - 1:
                            await asyncio.sleep(2 ** attempt)
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –¥–ª—è circuit breaker
                self.circuit_breaker_failures[endpoint.url] = \
                    self.circuit_breaker_failures.get(endpoint.url, 0) + 1
                
                return {
                    "error": "Max retries exceeded",
                    "url": endpoint.url,
                    "retries": endpoint.retries
                }
    
    async def fetch_multiple(
        self, 
        endpoints: List[APIEndpoint],
        progress_callback: Optional[Callable[[int, int], None]] = None
    ) -> List[Dict[str, Any]]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.
        
        Args:
            endpoints: –°–ø–∏—Å–æ–∫ endpoint –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤
            progress_callback: Callback –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        async with self.session() as session:
            tasks = []
            
            for i, endpoint in enumerate(endpoints):
                cache_key = f"{endpoint.method}:{endpoint.url}"
                task = self.fetch_single(endpoint, session, cache_key)
                tasks.append(task)
            
            results = []
            completed = 0
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –º–µ—Ä–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
            for coro in asyncio.as_completed(tasks):
                result = await coro
                results.append(result)
                completed += 1
                
                if progress_callback:
                    progress_callback(completed, len(endpoints))
            
            return results
    
    def clear_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à."""
        self.cache.clear()
        self.logger.info("Cache cleared")
    
    def get_circuit_breaker_status(self) -> Dict[str, int]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å circuit breaker –¥–ª—è –≤—Å–µ—Ö URL."""
        return self.circuit_breaker_failures.copy()''',
            
            "data_pipeline": '''import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Callable, Union
from pathlib import Path
from abc import ABC, abstractmethod

@dataclass
class DataQualityMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö."""
    completeness: float  # –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    uniqueness: float    # –ü—Ä–æ—Ü–µ–Ω—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    validity: float      # –ü—Ä–æ—Ü–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    consistency: float   # –ü—Ä–æ—Ü–µ–Ω—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    accuracy: float      # –ü—Ä–æ—Ü–µ–Ω—Ç —Ç–æ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

class DataProcessor(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö."""
    
    @abstractmethod
    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ."""
        pass
    
    @abstractmethod
    def validate(self, data: pd.DataFrame) -> bool:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ."""
        pass

class DataCleaningProcessor(DataProcessor):
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö."""
    
    def __init__(self, 
                 remove_duplicates: bool = True,
                 fill_missing: bool = True,
                 outlier_threshold: float = 3.0):
        self.remove_duplicates = remove_duplicates
        self.fill_missing = fill_missing
        self.outlier_threshold = outlier_threshold
        self.logger = logging.getLogger(__name__)
    
    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        –û—á–∏—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, –ø—Ä–æ–ø—É—Å–∫–æ–≤ –∏ –≤—ã–±—Ä–æ—Å–æ–≤.
        
        Args:
            data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –û—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        cleaned_data = data.copy()
        original_shape = cleaned_data.shape
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        if self.remove_duplicates:
            before_dedup = len(cleaned_data)
            cleaned_data = cleaned_data.drop_duplicates()
            after_dedup = len(cleaned_data)
            self.logger.info(f"Removed {before_dedup - after_dedup} duplicates")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        if self.fill_missing:
            for column in cleaned_data.columns:
                if cleaned_data[column].dtype in ['int64', 'float64']:
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –º–µ–¥–∏–∞–Ω–æ–π –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    median_value = cleaned_data[column].median()
                    cleaned_data[column].fillna(median_value, inplace=True)
                else:
                    # –ó–∞–ø–æ–ª–Ω—è–µ–º –º–æ–¥–æ–π –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    mode_value = cleaned_data[column].mode().iloc[0] if not cleaned_data[column].mode().empty else 'Unknown'
                    cleaned_data[column].fillna(mode_value, inplace=True)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫)
        numeric_columns = cleaned_data.select_dtypes(include=[np.number]).columns
        for column in numeric_columns:
            z_scores = np.abs((cleaned_data[column] - cleaned_data[column].mean()) / cleaned_data[column].std())
            cleaned_data = cleaned_data[z_scores < self.outlier_threshold]
        
        final_shape = cleaned_data.shape
        self.logger.info(f"Data shape changed from {original_shape} to {final_shape}")
        
        return cleaned_data
    
    def validate(self, data: pd.DataFrame) -> bool:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
        if data.empty:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–ø—É—Å–∫–æ–≤
        critical_missing_threshold = 0.5
        for column in data.columns:
            missing_ratio = data[column].isnull().sum() / len(data)
            if missing_ratio > critical_missing_threshold:
                self.logger.error(f"Column {column} has {missing_ratio:.2%} missing values")
                return False
        
        return True

class DataPipeline:
    """
    –ö–æ–Ω–≤–µ–π–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –¶–µ–ø–æ—á–∫—É –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    - –í–∞–ª–∏–¥–∞—Ü–∏—é –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ
    - –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
    - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
    - –û—Ç–∫–∞—Ç –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    """
    
    def __init__(self, name: str):
        self.name = name
        self.processors: List[DataProcessor] = []
        self.logger = logging.getLogger(__name__)
        self.processing_history: List[Dict[str, Any]] = []
    
    def add_processor(self, processor: DataProcessor) -> 'DataPipeline':
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤ –∫–æ–Ω–≤–µ–π–µ—Ä."""
        self.processors.append(processor)
        self.logger.info(f"Added processor {processor.__class__.__name__} to pipeline {self.name}")
        return self
    
    def calculate_quality_metrics(self, data: pd.DataFrame) -> DataQualityMetrics:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            data: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        """
        total_cells = data.size
        
        # Completeness - –ø—Ä–æ—Ü–µ–Ω—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        filled_cells = total_cells - data.isnull().sum().sum()
        completeness = filled_cells / total_cells if total_cells > 0 else 0
        
        # Uniqueness - —Å—Ä–µ–¥–Ω–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º
        uniqueness_scores = []
        for column in data.columns:
            unique_ratio = data[column].nunique() / len(data) if len(data) > 0 else 0
            uniqueness_scores.append(unique_ratio)
        uniqueness = np.mean(uniqueness_scores) if uniqueness_scores else 0
        
        # Validity - –ø—Ä–æ—Ü–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–±–µ–∑ NaN –∏ inf)
        valid_cells = total_cells - data.isnull().sum().sum()
        if data.select_dtypes(include=[np.number]).size > 0:
            valid_cells -= np.isinf(data.select_dtypes(include=[np.number])).sum().sum()
        validity = valid_cells / total_cells if total_cells > 0 else 0
        
        # Consistency –∏ Accuracy - —É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        consistency = 0.9  # Placeholder - —Ç—Ä–µ–±—É–µ—Ç –¥–æ–º–µ–Ω–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π
        accuracy = 0.85    # Placeholder - —Ç—Ä–µ–±—É–µ—Ç —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        
        return DataQualityMetrics(
            completeness=completeness,
            uniqueness=uniqueness,
            validity=validity,
            consistency=consistency,
            accuracy=accuracy
        )
    
    def process(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            data: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –∏—Å—Ç–æ—Ä–∏–µ–π
        """
        if data.empty:
            raise ValueError("Input data is empty")
        
        current_data = data.copy()
        processing_steps = []
        
        # –ù–∞—á–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        initial_metrics = self.calculate_quality_metrics(current_data)
        processing_steps.append({
            "step": "initial",
            "processor": "none",
            "shape": current_data.shape,
            "quality_metrics": initial_metrics
        })
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –∫–∞–∂–¥—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        for i, processor in enumerate(self.processors):
            step_name = f"step_{i+1}_{processor.__class__.__name__}"
            
            try:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –æ—Ç–∫–∞—Ç–∞
                backup_data = current_data.copy()
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                processed_data = processor.process(current_data)
                
                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if not processor.validate(processed_data):
                    self.logger.error(f"Validation failed for {processor.__class__.__name__}")
                    current_data = backup_data  # –û—Ç–∫–∞—Ç
                    continue
                
                current_data = processed_data
                
                # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
                step_metrics = self.calculate_quality_metrics(current_data)
                
                processing_steps.append({
                    "step": step_name,
                    "processor": processor.__class__.__name__,
                    "shape": current_data.shape,
                    "quality_metrics": step_metrics
                })
                
                self.logger.info(f"Completed {step_name}: shape {current_data.shape}")
                
            except Exception as e:
                self.logger.error(f"Error in {processor.__class__.__name__}: {e}")
                processing_steps.append({
                    "step": step_name,
                    "processor": processor.__class__.__name__,
                    "error": str(e)
                })
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        final_metrics = self.calculate_quality_metrics(current_data)
        
        result = {
            "pipeline_name": self.name,
            "processed_data": current_data,
            "initial_shape": data.shape,
            "final_shape": current_data.shape,
            "initial_quality": initial_metrics,
            "final_quality": final_metrics,
            "processing_steps": processing_steps,
            "success": len(processing_steps) > 1  # –ë–æ–ª—å—à–µ —á–µ–º —Ç–æ–ª—å–∫–æ initial step
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.processing_history.append({
            "timestamp": pd.Timestamp.now(),
            "initial_shape": data.shape,
            "final_shape": current_data.shape,
            "quality_improvement": final_metrics.completeness - initial_metrics.completeness
        })
        
        return result
    
    def get_processing_history(self) -> List[Dict[str, Any]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        return self.processing_history.copy()
    
    def export_metrics(self, filepath: Union[str, Path]) -> None:
        """–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON —Ñ–∞–π–ª."""
        metrics_data = {
            "pipeline_name": self.name,
            "processors": [p.__class__.__name__ for p in self.processors],
            "history": self.processing_history
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(metrics_data, f, indent=2, default=str)
        
        self.logger.info(f"Metrics exported to {filepath}")'''
        }
        
        # –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏
        self.problematic_code_examples = {
            "security_issues": '''import os
import subprocess

# –ü–†–û–ë–õ–ï–ú–ê: Hardcoded credentials
API_KEY = "sk-1234567890abcdef"
DATABASE_URL = "postgresql://admin:password123@localhost/db"

def execute_command(user_input):
    # –ü–†–û–ë–õ–ï–ú–ê: Command injection vulnerability
    result = subprocess.run(f"ls {user_input}", shell=True, capture_output=True)
    return result.stdout

def unsafe_file_read(filename):
    # –ü–†–û–ë–õ–ï–ú–ê: Path traversal vulnerability
    with open(f"/data/{filename}", 'r') as f:
        return f.read()

def eval_user_code(code):
    # –ü–†–û–ë–õ–ï–ú–ê: Code injection
    return eval(code)''',
            
            "performance_issues": '''import time

def inefficient_search(data, target):
    # –ü–†–û–ë–õ–ï–ú–ê: O(n¬≤) complexity
    for i in range(len(data)):
        for j in range(len(data)):
            if data[i] == target and data[j] == target:
                return i, j
    return None

def memory_leak_example():
    # –ü–†–û–ë–õ–ï–ú–ê: –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —É—Ç–µ—á–∫–∞ –ø–∞–º—è—Ç–∏
    global_cache = []
    while True:
        data = [i for i in range(10000)]
        global_cache.append(data)
        time.sleep(0.1)

def blocking_io():
    # –ü–†–û–ë–õ–ï–ú–ê: –ë–ª–æ–∫–∏—Ä—É—é—â–∏–π I/O –±–µ–∑ async
    import requests
    urls = ["http://example.com"] * 100
    results = []
    for url in urls:
        response = requests.get(url)
        results.append(response.text)
    return results''',
            
            "maintainability_issues": '''def process_data(d):
    # –ü–†–û–ë–õ–ï–ú–ê: –ù–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏, –Ω–µ—è—Å–Ω—ã–µ –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    r = []
    for x in d:
        if x > 0:
            y = x * 2
            if y > 10:
                z = y / 3
                r.append(z)
            else:
                r.append(y)
        else:
            r.append(0)
    return r

class DataProcessor:
    # –ü–†–û–ë–õ–ï–ú–ê: –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–µ–π
    def __init__(self):
        self.data = []
        self.results = []
        self.errors = []
        self.config = {}
        self.cache = {}
        self.logger = None
        self.db_connection = None
        self.api_client = None
    
    def process_everything(self, input_data, config, db_url, api_key):
        # –ü–†–û–ë–õ–ï–ú–ê: –ú–æ–Ω–æ–ª–∏—Ç–Ω—ã–π –º–µ—Ç–æ–¥
        try:
            self.connect_to_db(db_url)
            self.setup_api(api_key)
            self.validate_input(input_data)
            self.clean_data(input_data)
            self.transform_data()
            self.enrich_data()
            self.validate_output()
            self.save_to_db()
            self.send_to_api()
            self.generate_report()
            self.cleanup()
        except:
            pass  # –ü–†–û–ë–õ–ï–ú–ê: –ü—É—Å—Ç–æ–π except'''
        }
    
    def test_advanced_code_quality(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞ –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö"""
        print("üß™ –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ –∞–≥–µ–Ω—Ç–æ–≤")
        print("=" * 70)
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –ø–æ–≤—ã—à–µ–Ω–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        advanced_tasks = [
            {
                "name": "design_patterns",
                "description": "–†–µ–∞–ª–∏–∑—É–π –ø–∞—Ç—Ç–µ—Ä–Ω Strategy –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–ª–∞—Ç–µ–∂–µ–π —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π",
                "complexity": "expert",
                "code_key": "design_patterns",
                "expected_patterns": ["ABC", "abstractmethod", "Enum", "type hints", "error handling"]
            },
            {
                "name": "async_architecture", 
                "description": "–°–æ–∑–¥–∞–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π API –∫–ª–∏–µ–Ω—Ç —Å circuit breaker –∏ rate limiting",
                "complexity": "expert",
                "code_key": "async_architecture",
                "expected_patterns": ["async", "await", "asyncio", "context manager", "semaphore"]
            },
            {
                "name": "data_pipeline",
                "description": "–†–∞–∑—Ä–∞–±–æ—Ç–∞–π data pipeline —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫",
                "complexity": "expert", 
                "code_key": "data_pipeline",
                "expected_patterns": ["pandas", "dataclass", "ABC", "logging", "metrics"]
            }
        ]
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–¥
        problematic_tasks = [
            {
                "name": "security_issues",
                "description": "–ö–æ–¥ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
                "complexity": "problematic",
                "code_key": "security_issues",
                "expected_issues": ["hardcoded credentials", "command injection", "path traversal"]
            },
            {
                "name": "performance_issues", 
                "description": "–ö–æ–¥ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                "complexity": "problematic",
                "code_key": "performance_issues",
                "expected_issues": ["O(n¬≤) complexity", "memory leak", "blocking I/O"]
            },
            {
                "name": "maintainability_issues",
                "description": "–ö–æ–¥ —Å –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏", 
                "complexity": "problematic",
                "code_key": "maintainability_issues",
                "expected_issues": ["no documentation", "unclear names", "monolithic method"]
            }
        ]
        
        results = {
            "advanced_tests": [],
            "problematic_tests": [],
            "advanced_average": 0.0,
            "problematic_average": 0.0,
            "expert_level_ready": False
        }
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –ø—Ä–∏–º–µ—Ä—ã
        print("\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è:")
        advanced_scores = []
        
        for task in advanced_tasks:
            print(f"\nüìù –≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –∑–∞–¥–∞—á–∞: {task['name']}")
            code = self.advanced_code_examples.get(task['code_key'], "")
            
            if code:
                quality_score = self._analyze_advanced_code_quality(code, task)
                advanced_scores.append(quality_score['total_score'])
                
                results["advanced_tests"].append({
                    "task": task['name'],
                    "complexity": task['complexity'],
                    "quality_score": quality_score,
                    "code_length": len(code)
                })
                
                print(f"{'‚úÖ' if quality_score['total_score'] >= 8.0 else '‚ö†Ô∏è'} –ö–∞—á–µ—Å—Ç–≤–æ: {quality_score['total_score']:.1f}/10")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–¥
        print(f"\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø—Ä–æ–±–ª–µ–º:")
        problematic_scores = []
        
        for task in problematic_tasks:
            print(f"\nüìù –ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–¥: {task['name']}")
            code = self.problematic_code_examples.get(task['code_key'], "")
            
            if code:
                quality_score = self._analyze_problematic_code(code, task)
                problematic_scores.append(quality_score['total_score'])
                
                results["problematic_tests"].append({
                    "task": task['name'],
                    "complexity": task['complexity'],
                    "quality_score": quality_score,
                    "detected_issues": quality_score.get('detected_issues', [])
                })
                
                print(f"‚ùå –ö–∞—á–µ—Å—Ç–≤–æ: {quality_score['total_score']:.1f}/10 (–æ–∂–∏–¥–∞–µ–º–æ –Ω–∏–∑–∫–æ–µ)")
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏
        if advanced_scores:
            results["advanced_average"] = sum(advanced_scores) / len(advanced_scores)
            results["expert_level_ready"] = results["advanced_average"] >= 8.5
        
        if problematic_scores:
            results["problematic_average"] = sum(problematic_scores) / len(problematic_scores)
        
        return results
    
    def _analyze_advanced_code_quality(self, code: str, task: Dict) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∫–æ–¥–∞"""
        quality_metrics = {
            "syntax_valid": 0,
            "architecture_patterns": 0,
            "error_handling": 0,
            "type_safety": 0,
            "documentation": 0,
            "performance_awareness": 0,
            "maintainability": 0,
            "security_awareness": 0,
            "total_score": 0
        }
        
        # 1. –°–∏–Ω—Ç–∞–∫—Å–∏—Å (1 –±–∞–ª–ª)
        try:
            ast.parse(code)
            quality_metrics["syntax_valid"] = 1.0
            print("  ‚úÖ –°–∏–Ω—Ç–∞–∫—Å–∏—Å –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω")
        except SyntaxError:
            print("  ‚ùå –°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏")
        
        # 2. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (2 –±–∞–ª–ª–∞)
        pattern_score = 0
        expected_patterns = task.get("expected_patterns", [])
        
        for pattern in expected_patterns:
            if pattern.lower() in code.lower():
                pattern_score += 0.4
        
        quality_metrics["architecture_patterns"] = min(2.0, pattern_score)
        print(f"  {'‚úÖ' if pattern_score >= 1.5 else '‚ö†Ô∏è'} –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {pattern_score:.1f}/2.0")
        
        # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ (1.5 –±–∞–ª–ª–∞)
        error_handling_score = 0
        if "try:" in code and "except" in code:
            error_handling_score += 0.5
        if "raise" in code:
            error_handling_score += 0.5
        if "ValueError" in code or "TypeError" in code or "Exception" in code:
            error_handling_score += 0.3
        if "logging" in code or "logger" in code:
            error_handling_score += 0.2
        
        quality_metrics["error_handling"] = min(1.5, error_handling_score)
        print(f"  {'‚úÖ' if error_handling_score >= 1.0 else '‚ö†Ô∏è'} –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫: {error_handling_score:.1f}/1.5")
        
        # 4. Type safety (1.5 –±–∞–ª–ª–∞)
        type_score = 0
        if "from typing import" in code or "typing." in code:
            type_score += 0.5
        if "->" in code:
            type_score += 0.5
        if ": " in code and "def " in code:
            type_score += 0.3
        if "Optional" in code or "Union" in code or "List" in code or "Dict" in code:
            type_score += 0.2
        
        quality_metrics["type_safety"] = min(1.5, type_score)
        print(f"  {'‚úÖ' if type_score >= 1.0 else '‚ö†Ô∏è'} Type safety: {type_score:.1f}/1.5")
        
        # 5. –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (1 –±–∞–ª–ª)
        doc_score = 0
        if '"""' in code:
            doc_score += 0.5
        if "Args:" in code and "Returns:" in code:
            doc_score += 0.3
        if "Raises:" in code:
            doc_score += 0.2
        
        quality_metrics["documentation"] = min(1.0, doc_score)
        print(f"  {'‚úÖ' if doc_score >= 0.7 else '‚ö†Ô∏è'} –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: {doc_score:.1f}/1.0")
        
        # 6. Performance awareness (1 –±–∞–ª–ª)
        perf_score = 0
        if "async" in code and "await" in code:
            perf_score += 0.4
        if "cache" in code.lower() or "Cache" in code:
            perf_score += 0.2
        if "semaphore" in code.lower() or "Semaphore" in code:
            perf_score += 0.2
        if "pool" in code.lower() or "Pool" in code:
            perf_score += 0.2
        
        quality_metrics["performance_awareness"] = min(1.0, perf_score)
        print(f"  {'‚úÖ' if perf_score >= 0.6 else '‚ö†Ô∏è'} Performance awareness: {perf_score:.1f}/1.0")
        
        # 7. Maintainability (1 –±–∞–ª–ª)
        maint_score = 0.8  # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É —Ñ—É–Ω–∫—Ü–∏–π
        try:
            tree = ast.parse(code)
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    if hasattr(node, 'end_lineno') and hasattr(node, 'lineno'):
                        func_length = node.end_lineno - node.lineno
                        if func_length > 50:
                            maint_score -= 0.2
        except:
            pass
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ
        if re.search(r'def [a-z_][a-z0-9_]*\(', code):
            maint_score += 0.1
        
        quality_metrics["maintainability"] = max(0.0, min(1.0, maint_score))
        print(f"  {'‚úÖ' if maint_score >= 0.7 else '‚ö†Ô∏è'} Maintainability: {maint_score:.1f}/1.0")
        
        # 8. Security awareness (0.5 –±–∞–ª–ª–∞)
        security_score = 0.3  # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ—á–µ–≤–∏–¥–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        if "eval(" not in code and "exec(" not in code:
            security_score += 0.1
        if "shell=True" not in code:
            security_score += 0.1
        
        quality_metrics["security_awareness"] = min(0.5, security_score)
        print(f"  {'‚úÖ' if security_score >= 0.4 else '‚ö†Ô∏è'} Security awareness: {security_score:.1f}/0.5")
        
        # –û–±—â–∏–π –±–∞–ª–ª
        total = sum(quality_metrics.values()) - quality_metrics["total_score"]
        quality_metrics["total_score"] = total
        
        return quality_metrics
    
    def _analyze_problematic_code(self, code: str, task: Dict) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–¥ –∏ –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã"""
        quality_metrics = {
            "syntax_valid": 0,
            "security_issues": 0,
            "performance_issues": 0,
            "maintainability_issues": 0,
            "detected_issues": [],
            "total_score": 0
        }
        
        detected_issues = []
        
        # 1. –°–∏–Ω—Ç–∞–∫—Å–∏—Å
        try:
            ast.parse(code)
            quality_metrics["syntax_valid"] = 1.0
        except SyntaxError:
            detected_issues.append("–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏")
        
        # 2. –ü—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        security_issues = 0
        if 'API_KEY = "' in code or 'password' in code.lower():
            detected_issues.append("Hardcoded credentials")
            security_issues += 1
        
        if "shell=True" in code:
            detected_issues.append("Command injection vulnerability")
            security_issues += 1
        
        if "eval(" in code or "exec(" in code:
            detected_issues.append("Code injection vulnerability")
            security_issues += 1
        
        if "/{" in code and "}" in code:  # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ path traversal
            detected_issues.append("Potential path traversal")
            security_issues += 1
        
        quality_metrics["security_issues"] = max(0, 3 - security_issues)  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
        
        # 3. –ü—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        performance_issues = 0
        if "for i in range(len(" in code and "for j in range(len(" in code:
            detected_issues.append("O(n¬≤) complexity")
            performance_issues += 1
        
        if "while True:" in code and "append" in code:
            detected_issues.append("Potential memory leak")
            performance_issues += 1
        
        if "requests.get" in code and "for" in code:
            detected_issues.append("Blocking I/O in loop")
            performance_issues += 1
        
        quality_metrics["performance_issues"] = max(0, 3 - performance_issues)
        
        # 4. –ü—Ä–æ–±–ª–µ–º—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏
        maintainability_issues = 0
        if '"""' not in code and "def " in code:
            detected_issues.append("Missing documentation")
            maintainability_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        if re.search(r'\b[a-z]\b', code):
            detected_issues.append("Unclear variable names")
            maintainability_issues += 1
        
        if "except:" in code:
            detected_issues.append("Bare except clause")
            maintainability_issues += 1
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        if code.count('\n') > 30 and "def " in code:
            detected_issues.append("Monolithic method")
            maintainability_issues += 1
        
        quality_metrics["maintainability_issues"] = max(0, 3 - maintainability_issues)
        quality_metrics["detected_issues"] = detected_issues
        
        # –û–±—â–∏–π –±–∞–ª–ª (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∏–∑–∫–∏–º –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –∫–æ–¥–∞)
        total = (quality_metrics["syntax_valid"] + 
                quality_metrics["security_issues"] + 
                quality_metrics["performance_issues"] + 
                quality_metrics["maintainability_issues"]) / 4 * 10
        
        quality_metrics["total_score"] = total
        
        print(f"  üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(detected_issues)}")
        for issue in detected_issues:
            print(f"    ‚ùå {issue}")
        
        return quality_metrics
    
    def generate_advanced_report(self, results: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç"""
        report = f"""# üéØ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ –∞–≥–µ–Ω—Ç–æ–≤

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

### üèÜ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å
- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞:** {results['advanced_average']:.1f}/10
- **–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–º –∑–∞–¥–∞—á–∞–º:** {'‚úÖ –î–ê' if results['expert_level_ready'] else '‚ùå –ù–ï–¢'}

### üîç –î–µ—Ç–µ–∫—Ü–∏—è –ø—Ä–æ–±–ª–µ–º
- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –∫–æ–¥–∞:** {results['problematic_average']:.1f}/10 (–æ–∂–∏–¥–∞–µ–º–æ –Ω–∏–∑–∫–∞—è)

## üéØ –≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

"""
        
        if results['expert_level_ready']:
            report += """### ‚úÖ –≠–ö–°–ü–ï–†–¢–ù–´–ô –£–†–û–í–ï–ù–¨ –î–û–°–¢–ò–ì–ù–£–¢!

–ê–≥–µ–Ω—Ç—ã –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—é—Ç —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥ **—ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è** —Å:
- –°–ª–æ–∂–Ω—ã–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
- –ú–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
- Type safety –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π

**–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å:** –ê–≥–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤—ã –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö enterprise –ø—Ä–æ–µ–∫—Ç–æ–≤.

"""
        else:
            report += f"""### ‚ö†Ô∏è –≠–ö–°–ü–ï–†–¢–ù–´–ô –£–†–û–í–ï–ù–¨ –ù–ï –î–û–°–¢–ò–ì–ù–£–¢

–¢–µ–∫—É—â–∞—è –æ—Ü–µ–Ω–∫–∞ {results['advanced_average']:.1f}/10 –Ω–µ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –ø–æ—Ä–æ–≥–∞ 8.5/10.

**–¢—Ä–µ–±—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏–µ –≤:**
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–º –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–∏  
- –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—à–∏–±–æ–∫
- Performance –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

"""
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        report += "## üìã –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∑–∞–¥–∞—á\n\n"
        
        for test in results['advanced_tests']:
            score = test['quality_score']
            report += f"### {test['task']} ({test['complexity']})\n"
            report += f"**–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞:** {score['total_score']:.1f}/10\n\n"
            
            report += "**–î–µ—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:**\n"
            report += f"- üîß –°–∏–Ω—Ç–∞–∫—Å–∏—Å: {score['syntax_valid']:.1f}/1.0\n"
            report += f"- üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã: {score['architecture_patterns']:.1f}/2.0\n"
            report += f"- üõ°Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫: {score['error_handling']:.1f}/1.5\n"
            report += f"- üè∑Ô∏è Type safety: {score['type_safety']:.1f}/1.5\n"
            report += f"- üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: {score['documentation']:.1f}/1.0\n"
            report += f"- ‚ö° Performance awareness: {score['performance_awareness']:.1f}/1.0\n"
            report += f"- üîß Maintainability: {score['maintainability']:.1f}/1.0\n"
            report += f"- üîí Security awareness: {score['security_awareness']:.1f}/0.5\n\n"
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø—Ä–æ–±–ª–µ–º
        report += "## üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø—Ä–æ–±–ª–µ–º\n\n"
        
        for test in results['problematic_tests']:
            report += f"### {test['task']}\n"
            report += f"**–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:** {test['quality_score']['total_score']:.1f}/10 (–Ω–∏–∑–∫–∞—è - –æ–∂–∏–¥–∞–µ–º–æ)\n"
            
            detected = test['quality_score'].get('detected_issues', [])
            if detected:
                report += "**–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:**\n"
                for issue in detected:
                    report += f"- ‚ùå {issue}\n"
            report += "\n"
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report += "## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è\n\n"
        
        if results['expert_level_ready']:
            report += """### –î–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è:
1. **–†–∞—Å—à–∏—Ä—è–π—Ç–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã** - –¥–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ GoF –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
2. **–£–≥–ª—É–±–ª—è–π—Ç–µ async** - –¥–æ–±–∞–≤—å—Ç–µ advanced concurrency patterns
3. **–£—Å–∏–ª–∏–≤–∞–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - –º–µ—Ç—Ä–∏–∫–∏, —Ç—Ä–µ–π—Å–∏–Ω–≥, –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
4. **–†–∞–∑–≤–∏–≤–∞–π—Ç–µ security** - –¥–æ–±–∞–≤—å—Ç–µ security-by-design –ø—Ä–∏–Ω—Ü–∏–ø—ã

"""
        else:
            report += """### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —É–ª—É—á—à–µ–Ω–∏—è –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è:
1. **–ò–∑—É—á–∏—Ç–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã** - Strategy, Factory, Observer, etc.
2. **–û—Å–≤–æ–π—Ç–µ async/await** - asyncio, aiohttp, concurrent.futures
3. **–£–ª—É—á—à–∏—Ç–µ error handling** - custom exceptions, retry logic, circuit breaker
4. **–î–æ–±–∞–≤—å—Ç–µ type safety** - –ø–æ–ª–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ type hints
5. **–í–Ω–µ–¥—Ä–∏—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - logging, metrics, health checks

"""
        
        report += f"""## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

{'‚úÖ **–≠–ö–°–ü–ï–†–¢–ù–´–ô –£–†–û–í–ï–ù–¨ –î–û–°–¢–ò–ì–ù–£–¢**' if results['expert_level_ready'] else '‚ö†Ô∏è **–¢–†–ï–ë–£–ï–¢–°–Ø –†–ê–ó–í–ò–¢–ò–ï –î–û –≠–ö–°–ü–ï–†–¢–ù–û–ì–û –£–†–û–í–ù–Ø**'}

–ê–≥–µ–Ω—Ç—ã {'–≥–æ—Ç–æ–≤—ã' if results['expert_level_ready'] else '–Ω–µ –≥–æ—Ç–æ–≤—ã'} –¥–ª—è —Ä–µ—à–µ–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –∑–∞–¥–∞—á –∏ enterprise —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏.

---
**–û—Ç—á–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω:** {time.strftime('%d.%m.%Y %H:%M')}
**–≠–∫—Å–ø–µ—Ä—Ç:** Senior Software Architect
"""
        
        return report

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ –∞–≥–µ–Ω—Ç–æ–≤")
    
    tester = AdvancedAgentCodeQualityTester()
    results = tester.test_advanced_code_quality()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report = tester.generate_advanced_report(results)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_file = f"ADVANCED_AGENT_CODE_QUALITY_REPORT_{time.strftime('%Y-%m-%d')}.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nüìÑ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {report_file}")
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüéØ –≠–ö–°–ü–ï–†–¢–ù–ê–Ø –û–¶–ï–ù–ö–ê: {results['advanced_average']:.1f}/10")
    print(f"üîç –î–ï–¢–ï–ö–¶–ò–Ø –ü–†–û–ë–õ–ï–ú: {results['problematic_average']:.1f}/10 (–æ–∂–∏–¥–∞–µ–º–æ –Ω–∏–∑–∫–∞—è)")
    print(f"üèÜ –≠–ö–°–ü–ï–†–¢–ù–´–ô –£–†–û–í–ï–ù–¨: {'‚úÖ –î–û–°–¢–ò–ì–ù–£–¢' if results['expert_level_ready'] else '‚ùå –ù–ï –î–û–°–¢–ò–ì–ù–£–¢'}")
    
    return results

if __name__ == "__main__":
    main()