name: CI

on:
  push:
    branches: [master, main]
  pull_request:
    branches: [master, main]
  workflow_dispatch:

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install linters
        run: |
          pip install flake8 black isort
      
      - name: Check formatting (black)
        run: black --check --diff agent_system/ agent_runtime/ tools/
        continue-on-error: true
      
      - name: Check imports (isort)
        run: isort --check-only --diff agent_system/ agent_runtime/ tools/
        continue-on-error: true
      
      - name: Lint (flake8)
        run: flake8 agent_system/ agent_runtime/ tools/ --max-line-length=120 --ignore=E501,W503,E203,E226,E302,E305,E402,E722,E741,F401,F541,F821,F841,W291,W292,W293,W391,W504,E128,E129

  unit-tests:
    name: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov
      
      - name: Run unit tests
        run: python -m pytest -q -m "not requires_torch"
        env:
          DIRECTOR_ACTIVE_MODE: "false"
          SHADOW_DIRECTOR_ENABLED: "false"

      - name: Run minimal eval (observability)
        run: |
          mkdir -p data/reports
          python tools/run_minimal_eval.py | tee data/reports/minimal_eval.txt
          if [ -n "${GITHUB_STEP_SUMMARY:-}" ]; then
            tail -n 2 data/reports/minimal_eval.txt | sed 's/^/MIN_EVAL: /' >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Run eval taxonomy
        run: python tools/eval_taxonomy.py

      - name: Generate decision dashboard
        run: python tools/decision_dashboard.py --out data/reports/dashboard_daily.md --fail-below-score 0.6

      - name: Seed decision events for TREND (CI-only)
        run: |
          python - << 'PY'
          import os, json, time
          os.makedirs("data", exist_ok=True)
          path = "data/decision_events.log"

          existing = []
          if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
              for line in f:
                line = line.strip()
                if not line:
                  continue
                try:
                  existing.append(json.loads(line))
                except Exception:
                  pass

          need = max(0, 5 - len(existing))
          if need == 0:
            print(f"Seed skipped: already have {len(existing)} events")
            raise SystemExit(0)

          now = time.time()
          new_events = []
          for i in range(need):
            new_events.append({
              "ts": now + i,
              "type": "director_decision",
              "agent": "director",
              "decision": f"CI seed decision #{len(existing)+i+1}",
              "confidence": 0.85,
              "score": 0.85,
              "prompt_tokens": 500,
              "completion_tokens": 200,
              "total_tokens": 700,
              "latency_ms": 2500,
              "risk_level": "LOW",
              "decision_class": "process",
              "risks": [],
              "next_step": "CI seed to satisfy min_required",
              "synthetic": True
            })

          with open(path, "a", encoding="utf-8") as f:
            for e in new_events:
              f.write(json.dumps(e, ensure_ascii=False) + "\n")

          print(f"Seed applied: appended {need} events (total now {len(existing)+need})")
          PY

      - name: Decision trend gate
        run: |
          mkdir -p data/reports
          python tools/decision_trend.py --fail-below-avg 0.6 --exclude-class legacy_unknown --emit-json --windows-minutes 1440 --policy-off --adaptive-risk-thresholds | tee data/reports/decision_trend.txt
          if grep -q "TREND: INSUFFICIENT_DATA" data/reports/decision_trend.txt; then
            echo "TREND_GATE: SOFT (insufficient_data)"
            if [ -n "${GITHUB_STEP_SUMMARY:-}" ]; then
              echo "TREND_GATE: SOFT (insufficient_data)" >> "$GITHUB_STEP_SUMMARY"
            fi
            exit 0
          fi

      - name: Generate remediation plan
        run: |
          if [ -f data/reports/rca_action_priority.txt ]; then
            export RCA_ACTION_PRIORITY=$(sed 's/^RCA_ACTION_PRIORITY: //' data/reports/rca_action_priority.txt)
          fi
          python tools/generate_remediation_plan.py
          if [ -n "${GITHUB_STEP_SUMMARY:-}" ]; then
            if [ -f data/reports/remediation_plan.json ]; then
              N=$(python -c "import json; print(len(json.load(open('data/reports/remediation_plan.json'))['items']))")
              echo "REMEDIATION_PLAN: items=$N" >> "$GITHUB_STEP_SUMMARY"
            else
              echo "REMEDIATION_PLAN: items=0" >> "$GITHUB_STEP_SUMMARY"
            fi
          fi

      - name: Generate intelligence manifest
        run: |
          python tools/generate_intelligence_manifest.py
          if [ -n "${GITHUB_STEP_SUMMARY:-}" ]; then
            if [ -f data/reports/intelligence_manifest.json ]; then
              FIELDS=$(python -c "import json; d=json.load(open('data/reports/intelligence_manifest.json')); print(f\"backend={d.get('llm_backend','unknown')} lora={d.get('lora_adapter_path','unknown')}\")")
              echo "INTELLIGENCE: ${FIELDS}" >> "$GITHUB_STEP_SUMMARY"
            else
              echo "INTELLIGENCE: unknown" >> "$GITHUB_STEP_SUMMARY"
            fi
          fi

      - name: Append intelligence timeline
        run: |
          python tools/append_intelligence_timeline.py
          if [ -n "${GITHUB_STEP_SUMMARY:-}" ]; then
            if [ -f data/reports/intelligence_timeline.jsonl ]; then
              N=$(wc -l < data/reports/intelligence_timeline.jsonl | tr -d ' ')
              echo "INTEL_TIMELINE: lines=$N" >> "$GITHUB_STEP_SUMMARY"
            else
              echo "INTEL_TIMELINE: lines=0" >> "$GITHUB_STEP_SUMMARY"
            fi
          fi

      - name: Director autolink smoke (CI)
        run: |
          python - <<'PY'
          import time
          from agent_system.decision_log import append_decision_event
          try:
              from agent_system.director_adapter import DirectorAdapter, DirectorRequest, RiskLevel
              d = DirectorAdapter()
              req = DirectorRequest(
                  problem_summary="CI autolink smoke test",
                  facts=["ci"],
                  agent_summaries={"dev": "ok"},
                  risk_level=RiskLevel.LOW,
                  confidence=0.5,
              )
              res = d.call_director(req)
              print("AUTOLINK_SMOKE: director_call_ok")
          except Exception as exc:
              append_decision_event({
                  "type": "director_decision",
                  "agent": "director",
                  "decision": "CI autolink smoke (record-only)",
                  "next_step": "none",
                  "confidence": 0.5,
                  "prompt_tokens": 500,
                  "completion_tokens": 200,
                  "total_tokens": 700,
                  "latency_ms": 2500,
                  "synthetic": True,
                  "risk_level": "low",
                  "decision_class": "process",
                  "risks": [],
              })
              print(f"AUTOLINK_SMOKE: fallback_record_only ({exc})")
          PY

      - name: Latency smoke (observability)
        run: |
          python tools/latency_smoke.py | tee data/reports/latency_smoke.txt
          if [ -n "${GITHUB_STEP_SUMMARY:-}" ]; then
            tail -n 1 data/reports/latency_smoke.txt >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Cost smoke (observability)
        run: |
          python tools/cost_smoke.py | tee data/reports/cost_smoke.txt
          if [ -n "${GITHUB_STEP_SUMMARY:-}" ]; then
            cat data/reports/cost_smoke.txt >> "$GITHUB_STEP_SUMMARY"
          fi

      - name: Upload decision trend baseline
        uses: actions/upload-artifact@v4
        with:
          name: decision_trend_baseline_${{ github.sha }}
          path: data/reports/decision_trend_baseline.json
          if-no-files-found: warn

      - name: Upload decision dashboard
        uses: actions/upload-artifact@v4
        with:
          name: decision-dashboard-${{ github.run_id }}
          path: |
            data/reports/dashboard_daily.md
            data/reports/decision_trend.txt
            data/reports/remediation_plan.json
            data/reports/eval_fails_taxonomy.jsonl
            data/reports/intelligence_manifest.json
            data/reports/intelligence_timeline.jsonl
            data/reports/intelligence_report.md
            data/reports/training_pack.json
            data/reports/rollback_plan.json
            data/reports/adaptive_threshold_state.json
          if-no-files-found: ignore

  security-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Check for secrets
        run: |
          # Check for hardcoded API keys
          if grep -rE "sk-[a-zA-Z0-9]{20,}" --include="*.py" --include="*.md" .; then
            echo "::error::Potential API key found in code!"
            exit 1
          fi
          
          # Check for hardcoded passwords
          if grep -rE "password\s*=\s*['\"][^'\"]+['\"]" --include="*.py" . | grep -v "your_" | grep -v "example" | grep -v "test"; then
            echo "::warning::Potential hardcoded password found"
          fi
          
          echo "Security check passed"
